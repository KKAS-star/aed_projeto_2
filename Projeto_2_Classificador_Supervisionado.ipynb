{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "Projeto #2 - Classificador Supervisionado",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KKAS-star/aed_projeto_2/blob/master/Projeto_2_Classificador_Supervisionado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoWj0CchcCLI",
        "colab_type": "text"
      },
      "source": [
        "# Projeto #2 - Classificador supervisionado\n",
        "\n",
        "Antes de começar, leia as [Instruções](https://github.com/thvmm/pos-ds-ia/tree/master/projeto_2#instru%C3%A7%C3%B5es) e os [Critérios de Avaliação](https://github.com/thvmm/pos-ds-ia/tree/master/projeto_2#crit%C3%A9rios-de-avalia%C3%A7%C3%A3o)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kW-V79ucCLQ",
        "colab_type": "text"
      },
      "source": [
        "### 1) Qual a base escolhida?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip9WqbkOcCLT",
        "colab_type": "text"
      },
      "source": [
        "Forest covertypes - https://archive.ics.uci.edu/ml/datasets/Covertype -\n",
        "previsão do tipo de cobertura florestal a partir de variáveis cartográficas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6-IKZTjcCLV",
        "colab_type": "text"
      },
      "source": [
        "### 2) **(10%)** Pré-processamento: entendimento do conjunto de dados\n",
        "\n",
        "- Conversão do tipo de dados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rci1L-yxS_9_",
        "colab_type": "text"
      },
      "source": [
        "- Quais são minhas features?\n",
        "\n",
        "Name / Data Type / Measurement / Description\n",
        "\n",
        "- Elevation / quantitative /meters / Elevation in meters\n",
        "- Aspect / quantitative / azimuth / Aspect in degrees azimuth\n",
        "- Slope / quantitative / degrees / Slope in degrees\n",
        "- Horizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water features\n",
        "- Vertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water features\n",
        "- Horizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadway\n",
        "- Hillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solstice\n",
        "- Hillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer soltice\n",
        "- Hillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solstice\n",
        "- Horizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition points\n",
        "- Wilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designation\n",
        "- Soil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designation\n",
        "- Cover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhS6O931Tout",
        "colab_type": "text"
      },
      "source": [
        "- Quais são minhas classes?\n",
        "\n",
        "- Cover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugmMuMOdUVML",
        "colab_type": "text"
      },
      "source": [
        "- Como estão distribuidas minhas classes?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z_FJXnETvS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BIBLIOTECAS DATA SCIENCE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Importando o módulo train_test_split do sklearn para dividir dados de treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Usando o módulo Random Foresr para chamar o classificador\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Avaliando o resultado: Cross validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Técnica de redução da dimensionalidade: PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Técnica de normalização\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#GridSearch\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#MLP\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# BIBLIOTECAS DE PLOT\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djVYExt-TyD9",
        "colab_type": "code",
        "outputId": "52503f29-26fe-4ad5-d409-7d7f2a8ab6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " # OBS.: O TRECHO DE CÓDIGO ABAIXO SÓ É NECESSÁRIO REALIZAR SE ESTIVER USANDO O AMBIENTE DO GOOGLE COLAB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "arquivo_base = \"/content/drive/My Drive/POS IA/PROJETO_02/covtype.data\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f193hvMQUPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(arquivo_base, header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mbr1dWrdhaL",
        "colab_type": "code",
        "outputId": "eaca7f40-f033-413c-8c68-0f6667c753ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2579</td>\n",
              "      <td>132</td>\n",
              "      <td>6</td>\n",
              "      <td>300</td>\n",
              "      <td>-15</td>\n",
              "      <td>67</td>\n",
              "      <td>230</td>\n",
              "      <td>237</td>\n",
              "      <td>140</td>\n",
              "      <td>6031</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2606</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>270</td>\n",
              "      <td>5</td>\n",
              "      <td>633</td>\n",
              "      <td>222</td>\n",
              "      <td>225</td>\n",
              "      <td>138</td>\n",
              "      <td>6256</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2605</td>\n",
              "      <td>49</td>\n",
              "      <td>4</td>\n",
              "      <td>234</td>\n",
              "      <td>7</td>\n",
              "      <td>573</td>\n",
              "      <td>222</td>\n",
              "      <td>230</td>\n",
              "      <td>144</td>\n",
              "      <td>6228</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2617</td>\n",
              "      <td>45</td>\n",
              "      <td>9</td>\n",
              "      <td>240</td>\n",
              "      <td>56</td>\n",
              "      <td>666</td>\n",
              "      <td>223</td>\n",
              "      <td>221</td>\n",
              "      <td>133</td>\n",
              "      <td>6244</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2612</td>\n",
              "      <td>59</td>\n",
              "      <td>10</td>\n",
              "      <td>247</td>\n",
              "      <td>11</td>\n",
              "      <td>636</td>\n",
              "      <td>228</td>\n",
              "      <td>219</td>\n",
              "      <td>124</td>\n",
              "      <td>6230</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1   2    3    4     5    6    7   ...  47  48  49  50  51  52  53  54\n",
              "0  2596   51   3  258    0   510  221  232  ...   0   0   0   0   0   0   0   5\n",
              "1  2590   56   2  212   -6   390  220  235  ...   0   0   0   0   0   0   0   5\n",
              "2  2804  139   9  268   65  3180  234  238  ...   0   0   0   0   0   0   0   2\n",
              "3  2785  155  18  242  118  3090  238  238  ...   0   0   0   0   0   0   0   2\n",
              "4  2595   45   2  153   -1   391  220  234  ...   0   0   0   0   0   0   0   5\n",
              "5  2579  132   6  300  -15    67  230  237  ...   0   0   0   0   0   0   0   2\n",
              "6  2606   45   7  270    5   633  222  225  ...   0   0   0   0   0   0   0   5\n",
              "7  2605   49   4  234    7   573  222  230  ...   0   0   0   0   0   0   0   5\n",
              "8  2617   45   9  240   56   666  223  221  ...   0   0   0   0   0   0   0   5\n",
              "9  2612   59  10  247   11   636  228  219  ...   0   0   0   0   0   0   0   5\n",
              "\n",
              "[10 rows x 55 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyCzL0vF9AdV",
        "colab_type": "code",
        "outputId": "e4443ab4-663c-404f-b7eb-b35412ca06f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "df[54].value_counts() / df.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    0.487599\n",
              "1    0.364605\n",
              "3    0.061537\n",
              "7    0.035300\n",
              "6    0.029891\n",
              "5    0.016339\n",
              "4    0.004728\n",
              "Name: 54, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "703hxK0-_Am2",
        "colab_type": "code",
        "outputId": "b0b5d472-070c-40ff-9c45-025cad6dfe0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "df[54].value_counts(dropna=False).plot(kind=\"bar\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f48db5c8908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD1CAYAAAClSgmzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvfh9OXCibZIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7HUqo6P7nXG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "- Checagem se os valores estão dentro de um limite permitido ou razoável.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr6dD8dheHt6",
        "colab_type": "code",
        "outputId": "40ffdfc2-57a8-431d-b70b-9fa622f2488b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# qual o tamanho da nossa base?\n",
        "print('Número de linhas e número de colunas:', df.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de linhas e número de colunas: (581012, 55)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmfvRxV8eFDl",
        "colab_type": "code",
        "outputId": "4a99fbdc-dec3-479c-c627-3e5e0c1021a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "            51, 52, 53, 54],\n",
              "           dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tymnIpVNYWTr",
        "colab_type": "code",
        "outputId": "6999bcb4-9475-4946-8ac4-bbccaac88cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "#Informações estatísticas da base de dados\n",
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "      <td>581012.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2959.365301</td>\n",
              "      <td>155.656807</td>\n",
              "      <td>14.103704</td>\n",
              "      <td>269.428217</td>\n",
              "      <td>46.418855</td>\n",
              "      <td>2350.146611</td>\n",
              "      <td>212.146049</td>\n",
              "      <td>223.318716</td>\n",
              "      <td>142.528263</td>\n",
              "      <td>1980.291226</td>\n",
              "      <td>0.448865</td>\n",
              "      <td>0.051434</td>\n",
              "      <td>0.436074</td>\n",
              "      <td>0.063627</td>\n",
              "      <td>0.005217</td>\n",
              "      <td>0.012952</td>\n",
              "      <td>0.008301</td>\n",
              "      <td>0.021335</td>\n",
              "      <td>0.002749</td>\n",
              "      <td>0.011316</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>0.001974</td>\n",
              "      <td>0.056168</td>\n",
              "      <td>0.021359</td>\n",
              "      <td>0.051584</td>\n",
              "      <td>0.030001</td>\n",
              "      <td>0.001031</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.004897</td>\n",
              "      <td>0.005890</td>\n",
              "      <td>0.003268</td>\n",
              "      <td>0.006921</td>\n",
              "      <td>0.015936</td>\n",
              "      <td>0.001442</td>\n",
              "      <td>0.057439</td>\n",
              "      <td>0.099399</td>\n",
              "      <td>0.036622</td>\n",
              "      <td>0.000816</td>\n",
              "      <td>0.004456</td>\n",
              "      <td>0.001869</td>\n",
              "      <td>0.001628</td>\n",
              "      <td>0.198356</td>\n",
              "      <td>0.051927</td>\n",
              "      <td>0.044175</td>\n",
              "      <td>0.090392</td>\n",
              "      <td>0.077716</td>\n",
              "      <td>0.002773</td>\n",
              "      <td>0.003255</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.000513</td>\n",
              "      <td>0.026803</td>\n",
              "      <td>0.023762</td>\n",
              "      <td>0.015060</td>\n",
              "      <td>2.051471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>279.984734</td>\n",
              "      <td>111.913721</td>\n",
              "      <td>7.488242</td>\n",
              "      <td>212.549356</td>\n",
              "      <td>58.295232</td>\n",
              "      <td>1559.254870</td>\n",
              "      <td>26.769889</td>\n",
              "      <td>19.768697</td>\n",
              "      <td>38.274529</td>\n",
              "      <td>1324.195210</td>\n",
              "      <td>0.497379</td>\n",
              "      <td>0.220882</td>\n",
              "      <td>0.495897</td>\n",
              "      <td>0.244087</td>\n",
              "      <td>0.072039</td>\n",
              "      <td>0.113066</td>\n",
              "      <td>0.090731</td>\n",
              "      <td>0.144499</td>\n",
              "      <td>0.052356</td>\n",
              "      <td>0.105775</td>\n",
              "      <td>0.013442</td>\n",
              "      <td>0.017550</td>\n",
              "      <td>0.044387</td>\n",
              "      <td>0.230245</td>\n",
              "      <td>0.144579</td>\n",
              "      <td>0.221186</td>\n",
              "      <td>0.170590</td>\n",
              "      <td>0.032092</td>\n",
              "      <td>0.002272</td>\n",
              "      <td>0.069804</td>\n",
              "      <td>0.076518</td>\n",
              "      <td>0.057077</td>\n",
              "      <td>0.082902</td>\n",
              "      <td>0.125228</td>\n",
              "      <td>0.037950</td>\n",
              "      <td>0.232681</td>\n",
              "      <td>0.299197</td>\n",
              "      <td>0.187833</td>\n",
              "      <td>0.028551</td>\n",
              "      <td>0.066605</td>\n",
              "      <td>0.043193</td>\n",
              "      <td>0.040318</td>\n",
              "      <td>0.398762</td>\n",
              "      <td>0.221879</td>\n",
              "      <td>0.205483</td>\n",
              "      <td>0.286743</td>\n",
              "      <td>0.267725</td>\n",
              "      <td>0.052584</td>\n",
              "      <td>0.056957</td>\n",
              "      <td>0.014310</td>\n",
              "      <td>0.022641</td>\n",
              "      <td>0.161508</td>\n",
              "      <td>0.152307</td>\n",
              "      <td>0.121791</td>\n",
              "      <td>1.396504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1859.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-173.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2809.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1106.000000</td>\n",
              "      <td>198.000000</td>\n",
              "      <td>213.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>1024.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2996.000000</td>\n",
              "      <td>127.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>218.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1997.000000</td>\n",
              "      <td>218.000000</td>\n",
              "      <td>226.000000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>1710.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3163.000000</td>\n",
              "      <td>260.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>384.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>3328.000000</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>237.000000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>2550.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3858.000000</td>\n",
              "      <td>360.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>1397.000000</td>\n",
              "      <td>601.000000</td>\n",
              "      <td>7117.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>7173.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0              1   ...             53             54\n",
              "count  581012.000000  581012.000000  ...  581012.000000  581012.000000\n",
              "mean     2959.365301     155.656807  ...       0.015060       2.051471\n",
              "std       279.984734     111.913721  ...       0.121791       1.396504\n",
              "min      1859.000000       0.000000  ...       0.000000       1.000000\n",
              "25%      2809.000000      58.000000  ...       0.000000       1.000000\n",
              "50%      2996.000000     127.000000  ...       0.000000       2.000000\n",
              "75%      3163.000000     260.000000  ...       0.000000       2.000000\n",
              "max      3858.000000     360.000000  ...       1.000000       7.000000\n",
              "\n",
              "[8 rows x 55 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qExvDiv9dt-Q",
        "colab_type": "code",
        "outputId": "92720daa-c097-4267-bc3c-39bac28b7cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "# Verificação, com o uso do método isnull(), de valores faltantes ou nulos \n",
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "5     0\n",
              "6     0\n",
              "7     0\n",
              "8     0\n",
              "9     0\n",
              "10    0\n",
              "11    0\n",
              "12    0\n",
              "13    0\n",
              "14    0\n",
              "15    0\n",
              "16    0\n",
              "17    0\n",
              "18    0\n",
              "19    0\n",
              "20    0\n",
              "21    0\n",
              "22    0\n",
              "23    0\n",
              "24    0\n",
              "25    0\n",
              "26    0\n",
              "27    0\n",
              "28    0\n",
              "29    0\n",
              "30    0\n",
              "31    0\n",
              "32    0\n",
              "33    0\n",
              "34    0\n",
              "35    0\n",
              "36    0\n",
              "37    0\n",
              "38    0\n",
              "39    0\n",
              "40    0\n",
              "41    0\n",
              "42    0\n",
              "43    0\n",
              "44    0\n",
              "45    0\n",
              "46    0\n",
              "47    0\n",
              "48    0\n",
              "49    0\n",
              "50    0\n",
              "51    0\n",
              "52    0\n",
              "53    0\n",
              "54    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7GNHnbkE614",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Separando a coluna que contém o lable (\"Cover Type\")\n",
        "df[54]\n",
        "y = df[54]\n",
        "x = df\n",
        "x.drop(columns = 54,inplace=True,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejvpVNjpQDQ4",
        "colab_type": "code",
        "outputId": "3c4ac2d6-628a-4141-8754-f8b938234591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(581012, 54)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYTi5n-FcCLg",
        "colab_type": "text"
      },
      "source": [
        "### 3) **(80%)** Nos blocos seguintes implemente seus classificadores (serão implementados 2 métodos diferentes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2jIoBI4cCLi",
        "colab_type": "text"
      },
      "source": [
        "#### 3.1) Qual método escolhido?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnr7g3IgcCLl",
        "colab_type": "text"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yspDYIQtcCLn",
        "colab_type": "text"
      },
      "source": [
        "#### 3.2) **(10%)** Baseline - Implemente seu classificador da forma mais simples possível para esse ser seu baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H5ChppwWyEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#separa os dados em set de teste e de treino\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivIwTnfer6_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Usando o módulo Random Forest para chamar o classificador.\n",
        "clf = RandomForestClassifier(n_estimators = 100, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El8L8N1xr7EB",
        "colab_type": "code",
        "outputId": "d145fb4c-a9e0-42aa-a1d9-1cb7f58be905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Treinando o modelo com os dados de Treino\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGieno58r69C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testando o modelo\n",
        "predictions = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9gzGOACr63l",
        "colab_type": "code",
        "outputId": "4ee80834-620e-4f11-8337-46751b2d2188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Avaliando o resultado: acuracia.\n",
        "acuracia = accuracy_score(predictions, y_test)\n",
        "print(\"Acuracia de \", round(float(acuracia), 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuracia de  0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0Q3CMG1r67D",
        "colab_type": "code",
        "outputId": "b177cbbc-9a84-4a35-c301-d47ce746efd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Avaliando o resultado: cross validation\n",
        "scores = cross_val_score(clf, x, y, cv=5)\n",
        "print(\"Cross-validated scores\", scores)\n",
        "\n",
        "#Média dos scores do cross validation\n",
        "print(\"Cross-validated scores\", round(scores.mean(), 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores [0.62620586 0.55141434 0.55031755 0.5995766  0.63784616]\n",
            "Cross-validated scores 0.59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZeHCYnLcCLw",
        "colab_type": "text"
      },
      "source": [
        "#### 3.3) **(20%)** Versão 1 - O que podemos fazer para melhorar nosso baseline? Aplique técnicas como redução de dimensionalidade, normalização ou outras. Compare os resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFyppaksnjZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#separa os dados em set de teste e de treino\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zKnc9gX7LUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Técnica de redução da dimensionalidade: PCA\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "pca.fit(x)\n",
        "x = pca.transform(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNKjvMCScHfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0JvVhT7kG3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Técnica de normalização\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x)\n",
        "x = scaler.transform(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUjJlR1CwGjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb8_3KY30ZFo",
        "colab_type": "code",
        "outputId": "b80495c2-a47e-41a3-9133-e5b2eaf18577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Usando o módulo Random Forest para chamar o classificador.\n",
        "clf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
        "\n",
        "# Treinando o modelo com os dados de Treino\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Testando o modelo\n",
        "predictions = clf.predict(X_test)\n",
        "\n",
        "#Avaliando o resultado: acuracia.\n",
        "acuracia = accuracy_score(predictions, y_test)\n",
        "print(\"Acuracia de \", round(float(acuracia), 2))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuracia de  0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3AKuxMNnPET",
        "colab_type": "code",
        "outputId": "da4523c2-6082-4ac7-8723-0a7d56e54169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Avaliando o resultado: cross validation\n",
        "scores = cross_val_score(clf, x, y, cv=5)\n",
        "print(\"Cross-validated scores\", scores)\n",
        "\n",
        "#Média dos scores do cross validation\n",
        "print(\"Cross-validated scores\", round(scores.mean(), 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores [0.60376238 0.51683691 0.52842464 0.59887954 0.65029862]\n",
            "Cross-validated scores 0.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs2hctCOcCL5",
        "colab_type": "text"
      },
      "source": [
        "#### 3.4) **(10%)** Tunning - Agora que temos um resultado promissor, vamos tentar melhorar o resultado alterando um ou mais hiper-parametro. Compare os resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3PxIGkkcCL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GridSearchCV\n",
        "# Tipo de classificador: RandomForestClassifier\n",
        "clf = RandomForestClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl9oOSah-uSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Escolha dos parâmetros combinados\n",
        "parameters = {'n_estimators': [10, 100, 200], \n",
        "              'max_features': ['log2', 'sqrt','auto'], \n",
        "              'criterion': ['entropy', 'gini'],         \n",
        "             }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM-cGWML-0HK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tipo de scoring usado para comparar os parâmetros combinados\n",
        "acc_scorer = make_scorer(accuracy_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t9KTfOn-3yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rodando o grid search\n",
        "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\n",
        "grid_obj = grid_obj.fit(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjhG2uEI--DY",
        "colab_type": "code",
        "outputId": "b7d1c0bc-69b6-4a1b-add4-d0706c6d7c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Isolando no \"clf\" a melhor combinação de parâmetros\n",
        "clf_best = grid_obj.best_estimator_\n",
        "clf_best"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='log2',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEIFuNxF--PP",
        "colab_type": "code",
        "outputId": "8d04890c-6791-4f32-e5c8-a75967561106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Aplicando o melhor algoritmo aos dados. \n",
        "clf.fit(x, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='log2',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZQC7xDNHrp1",
        "colab_type": "code",
        "outputId": "36cabdf5-e7fd-4caf-df47-c44735a545fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#separa os dados em set de teste e de treino\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Usando o módulo Random Forest para chamar o classificador. O modelo foi instanciado com 100 decision trees\n",
        "clf = RandomForestClassifier(n_estimators = 200, max_features='log2', criterion='gini', random_state = 42)\n",
        "\n",
        "# Treinando o modelo com os dados de Treino\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Testando o modelo\n",
        "predictions = clf.predict(X_test)\n",
        "\n",
        "#Avaliando o resultado: acuracia.\n",
        "acuracia = accuracy_score(predictions, y_test)\n",
        "print(\"Acuracia de \", round(float(acuracia), 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuracia de  0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_219HU5cMzV",
        "colab_type": "code",
        "outputId": "70f3775d-0dd2-43ea-aafb-19fa23b363b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Avaliando o resultado: cross validation\n",
        "scores = cross_val_score(clf, x, y, cv=5)\n",
        "print(\"Cross-validated scores\", scores)\n",
        "\n",
        "#Média dos scores do cross validation\n",
        "print(\"Cross-validated scores\", round(scores.mean(), 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores [0.60376238 0.51683691 0.52842464 0.59887954 0.65029862]\n",
            "Cross-validated scores 0.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izqC0jyGcCMD",
        "colab_type": "text"
      },
      "source": [
        "#### 3.5) Qual método escolhido?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vzrj3r0cCME",
        "colab_type": "text"
      },
      "source": [
        "MLP - Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL3U49IScCMG",
        "colab_type": "text"
      },
      "source": [
        "#### 3.6) **(10%)** Baseline - Implemente seu classificador da forma mais simples possível para esse ser seu baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfYcAy-Vqgxf",
        "colab_type": "code",
        "outputId": "c1f24cd5-3191-4dbf-9afe-d6a0693dcb59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#separa os dados em set de teste e de treino\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Usando o módulo MLPClassifier para chamar o MLPClassifier.\n",
        "clf2 = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=100)\n",
        "\n",
        "# Treinando o modelo com os dados de Treino\n",
        "clf2.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# Testando o modelo\n",
        "predictions = clf2.predict(X_test)\n",
        "\n",
        "#Avaliando o resultado: acuracia.\n",
        "acuracia = accuracy_score(predictions, y_test)\n",
        "print(\"Acuracia de \", round(float(acuracia), 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Acuracia de  0.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shMbnCRkyzAo",
        "colab_type": "code",
        "outputId": "6f75284a-ef6e-427c-d006-4953d845b391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Avaliando o resultado: Cross validation\n",
        "scores = cross_val_score(clf, x, y, cv=5)\n",
        "print(\"Cross-validated scores\", scores)\n",
        "\n",
        "#Média dos scores do crossvalidation\n",
        "print(\"Cross-validated scores\", round(scores.mean(), 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores [0.68439985 0.57041066 0.69322387 0.62692553 0.49439769 0.62482573\n",
            " 0.62140066 0.59160772 0.58155626 0.67873186]\n",
            "Cross-validated scores 0.62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWbLNLY8cCMO",
        "colab_type": "text"
      },
      "source": [
        "#### 3.7) **(20%)** Versão 1 - O que podemos fazer para melhorar nosso baseline? Aplique técnicas como redução de dimensionalidade, normalização ou outras. Compare os resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwCVf_F_VHg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#separa os dados em set de teste e de treino\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIp1zcb2unNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Técnica de redução da dimensionalidade: PCA\n",
        "\n",
        "pca = PCA(n_components=40)\n",
        "pca.fit(x)\n",
        "x = pca.transform(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzTUtNWxwDtr",
        "colab_type": "code",
        "outputId": "0af7c2fa-ff6e-438a-9541-d0ef503afc5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Técnica de normalização\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "transformer = Normalizer().fit(x)\n",
        "transformer\n",
        "Normalizer()\n",
        "transformer.transform(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.12783922,  0.11720352, -0.09634863, ..., -0.01366609,\n",
              "         0.00229438,  0.02328137],\n",
              "       [-0.10517024,  0.09401435, -0.09136522, ..., -0.01303377,\n",
              "         0.00146352,  0.02404386],\n",
              "       [ 0.08317417,  0.49803706,  0.06107452, ..., -0.00932955,\n",
              "         0.00486876,  0.00470699],\n",
              "       ...,\n",
              "       [ 0.00133128, -0.32506202, -0.08293022, ..., -0.00610722,\n",
              "        -0.02760379,  0.0012812 ],\n",
              "       [ 0.03666149, -0.32514876, -0.08431147, ..., -0.00558664,\n",
              "        -0.02837954,  0.00175501],\n",
              "       [ 0.02411328, -0.32721259, -0.08509732, ..., -0.00488578,\n",
              "        -0.0287259 ,  0.00245623]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Z9amlOunjc",
        "colab_type": "code",
        "outputId": "e57c2561-6104-488d-96a3-1ea0dc68074a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Usando o módulo MLPClassifier para chamar o MLPClassifier.\n",
        "clf = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=100)\n",
        "\n",
        "# Treinando o modelo com os dados de Treino\n",
        "clf.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# Testando o modelo\n",
        "predictions = clf.predict(X_test)\n",
        "\n",
        "#Avaliando o resultado: acuracia.\n",
        "acuracia = accuracy_score(predictions, y_test)\n",
        "print(\"Acuracia de \", round(float(acuracia), 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Acuracia de  0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdbaH2fSZHK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e6391d8-4f33-4bfe-bfaf-fc2bd59f8af4"
      },
      "source": [
        "#Avaliando o resultado: Cross validation\n",
        "scores = cross_val_score(clf, x, y, cv=5)\n",
        "print(\"Cross-validated scores\", scores)\n",
        "\n",
        "#Média dos scores do crossvalidation\n",
        "print(\"Cross-validated scores\", round(scores.mean(), 2))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-validated scores [0.52820495 0.54444378 0.46444984 0.54536067 0.56376827]\n",
            "Cross-validated scores 0.53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLLv7F6McCMX",
        "colab_type": "text"
      },
      "source": [
        "#### 3.8) **(10%)** Tunning - Agora que temos um resultado promissor, vamos tentar melhorar o resultado alterando um ou mais hiper-parametro. Compare os resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWkakGXOTpFj",
        "colab_type": "code",
        "outputId": "dc1bba13-9948-41bd-f783-a9b221b1eb39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# GridSearchCV\n",
        "# Tipo de classificador: RandomForestClassifier\n",
        "clf = MLPClassifier()\n",
        "\n",
        "# Escolha dos parâmetros combinados\n",
        "parameters = {'max_fun': [10, 20, 50], \n",
        "              'max_iter': [10, 20, 50],                    \n",
        "             }\n",
        "\n",
        "# Tipo de scoring usado para comparar os parâmetros combinados\n",
        "acc_scorer = make_scorer(accuracy_score)\n",
        "\n",
        "# Rodando o grid search\n",
        "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\n",
        "grid_obj = grid_obj.fit(x, y)\n",
        "\n",
        "# Isolando no \"clf\" a melhor combinação de parâmetros\n",
        "clf_best = grid_obj.best_estimator_\n",
        "clf_best\n",
        "\n",
        "# Aplicando o melhor algoritmo aos dados. \n",
        "clf.fit(x, y)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl_XhD_ycC-m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12426aaf-6ff1-4b14-8f1f-690f3c6afeaa"
      },
      "source": [
        "#separa os dados em set de teste e de treino\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
        "\n",
        "# Usando o módulo MLPClassifier para chamar o classificador.\n",
        "clf2 = MLPClassifier(max_fun = 50, max_iter = 50, random_state = 42)\n",
        "\n",
        "# Treinando o modelo com os dados de Treino\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Testando o modelo\n",
        "predictions = clf.predict(X_test)\n",
        "\n",
        "#Avaliando o resultado: acuracia.\n",
        "acuracia = accuracy_score(predictions, y_test)\n",
        "print(\"Acuracia de \", round(float(acuracia), 2))\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuracia de  0.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdvYD_IEBGNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Avaliando o resultado: Cross validation\n",
        "scores = cross_val_score(clf, x, y, cv=5)\n",
        "print(\"Cross-validated scores\", scores)\n",
        "\n",
        "#Média dos scores do crossvalidation\n",
        "print(\"Cross-validated scores\", round(scores.mean(), 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmQ0q6YacCMe",
        "colab_type": "text"
      },
      "source": [
        "### 5) **(10%)** Conclusões"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fqF9-cFcCMg",
        "colab_type": "text"
      },
      "source": [
        "*Compare seus resultados. Imaginando que sua solução fosse para produção, qual deles você escolheria? Por que? Quais os riscos você enxerga? O que recomendaria de próximos passos para melhorar os resultados?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4aUgJyncCMi",
        "colab_type": "text"
      },
      "source": [
        "RandomForestClassifier: Acuracia de  0.95 e Cross-validated scores 0.59\n",
        "\n",
        "MLPClassifier: Acuracia de  0.91 e Cross-validated scores 0.62\n",
        "\n",
        "Caso a solução fosse para produção, eu escolheria o MLPClassifier, pois, apesar de sua acurácia ter apresentado resultado menor que do modelo RandomForestClassifier, seu Cross-validated foi maior, o que evidencia sua performace em produção seria ligeiramente superior.\n",
        "Contudo, considerando a considerável diferença entre os scores da acurácia e Cross-validated, em ambos os modelos, o que evidencia a existência de overfit, seria temerário aplicar em produção qualquer dos modelos em produção, pois ainda não apresentam desempenho satisfatório.\n",
        "Para a melhora dos resultados, o recomendável seria a aplicação de outras técnicas de pre-processamento dos dados, além observância de outros hiperparâmetros no GridSearchCV."
      ]
    }
  ]
}